# stage5_evaluation_prediction.py
# ç¬¬äº”é˜¶æ®µï¼šæ¨¡å‹ä¼˜åŒ–ã€å¤šç»´è¯„ä¼°ä¸æœ€ç»ˆé¢„æµ‹ (è·¯å¾„ä¿®æ­£ç‰ˆ)

import numpy as np
import pandas as pd
import os
import time
import pickle
import warnings
import sys

# æœºå™¨å­¦ä¹ æ¨¡å‹
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

warnings.filterwarnings('ignore')

# ================= 1. ç®€åŒ–çš„æµæ°´çº¿é‡å»º (Pipeline Reconstruction) =================
class EvaluationPipeline:
    """é‡å»ºä» åŸå§‹æ•°æ® -> SVD -> ç‰¹å¾ç­›é€‰ çš„å®Œæ•´æµæ°´çº¿"""
    
    def __init__(self, train_file):
        self.train_file = train_file
        self.mean = None
        self.std = None
        self.V_k = None # SVD æŠ•å½±çŸ©é˜µ
        self.selected_indices = None # ç‰¹å¾ç­›é€‰ç´¢å¼•
        self.scaler = None # æ ‡å‡†åŒ–å™¨
        self.models = {}
        self.X_train_final = None
        self.y_train = None
        self.valid_columns = None
        
    def fit_pipeline(self):
        """é‡æ–°æ‹Ÿåˆé¢„å¤„ç†å‚æ•° (ä¸ºäº†å¤„ç†æµ‹è¯•é›†)"""
        print(">>> [Pipeline] æ­£åœ¨é‡å»ºæ•°æ®é¢„å¤„ç†æµæ°´çº¿...")
        
        # 1. åŠ è½½åŸå§‹è®­ç»ƒæ•°æ®
        if not os.path.exists(self.train_file):
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {self.train_file}")
            return False
            
        print(f"   -> è¯»å–æ–‡ä»¶: {self.train_file}")
        try:
            df = pd.read_csv(self.train_file)
        except Exception as e:
            print(f"   -> è¯»å–å¤±è´¥: {e}")
            return False
        
        # 2. æ¸…æ´—é€»è¾‘ (ä¸é˜¶æ®µ2ä¸€è‡´)
        drop_cols = ['time', 'group_name', 'light_is_daytime']
        cols_to_drop = [c for c in drop_cols if c in df.columns]
        if cols_to_drop:
            df = df.drop(columns=cols_to_drop)
        
        # å¼ºåŠ›æ¸…æ´—
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df_num = df[numeric_cols].fillna(df[numeric_cols].mean()).fillna(0)
        
        # å‰”é™¤é«˜æ–¹å·®å’Œå¸¸é‡åˆ—
        variances = df_num.var()
        bad_cols = variances[(variances > 1e9) | (variances == 0)].index
        if len(bad_cols) > 0:
            df_num = df_num.drop(columns=bad_cols)
            
        self.valid_columns = df_num.columns.drop('labelArea') if 'labelArea' in df_num.columns else df_num.columns
        
        X = df_num.drop(columns=['labelArea']).values
        y = df_num['labelArea'].values
        
        # 3. æ‹Ÿåˆ SVD (ç®€åŒ–ç‰ˆ)
        print("   -> æ‹Ÿåˆ SVD å‚æ•°...")
        self.mean = np.mean(X, axis=0)
        self.std = np.std(X, axis=0)
        self.std[self.std == 0] = 1.0
        X_std = (X - self.mean) / self.std
        
        # å¿«é€Ÿ SVD
        # ä½¿ç”¨ numpy.linalg.svd è®¡ç®—ç›¸å…³æ€§çŸ©é˜µçš„ç‰¹å¾å‘é‡
        cov_matrix = (X_std.T @ X_std) / (X.shape[0]-1)
        U, S, Vt = np.linalg.svd(cov_matrix)
        
        # å‡è®¾é˜¶æ®µ2é€‰äº† k=80 (æ ¹æ®ä½ çš„æ—¥å¿—)
        k = min(80, X.shape[1])
        self.V_k = Vt.T[:, :k] # (n_features, k)
        
        X_svd = X_std @ self.V_k
        
        X_final = X_svd
        
        # 5. æ‹Ÿåˆæ ‡å‡†åŒ–å™¨
        self.scaler = StandardScaler()
        self.X_train_final = self.scaler.fit_transform(X_final)
        self.y_train = y
        
        print(">>> [Pipeline] æµæ°´çº¿é‡å»ºå®Œæˆã€‚")
        return True

    def train_models(self):
        """å¿«é€Ÿé‡æ–°è®­ç»ƒæ¨¡å‹"""
        print(">>> [Models] æ­£åœ¨é‡æ–°è®­ç»ƒæ¨¡å‹...")
        
        # 1. éšæœºæ£®æ— (RF)
        rf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)
        rf.fit(self.X_train_final, self.y_train)
        self.models['RandomForest'] = rf
        
        # 2. ç¥ç»ç½‘ç»œ (MLP)
        mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=200, random_state=42)
        mlp.fit(self.X_train_final, self.y_train)
        self.models['NeuralNet'] = mlp
        
        # 3. é€»è¾‘å›å½’ (æ¨¡æ‹Ÿ LU-LR)
        from sklearn.linear_model import LogisticRegression
        lr = LogisticRegression(solver='newton-cg', max_iter=20)
        lr.fit(self.X_train_final, self.y_train)
        self.models['LU-Logistic'] = lr
        
        print(">>> [Models] æ¨¡å‹å‡†å¤‡å°±ç»ªã€‚")

    def process_test_data(self, raw_df):
        """å°†åŸå§‹æµ‹è¯•æ•°æ®é€šè¿‡æµæ°´çº¿è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥"""
        # 1. å¯¹é½åˆ— (ç¼ºå¤±çš„åˆ—è¡¥0ï¼Œå¤šä½™çš„åˆ—å¿½ç•¥)
        #åˆ›å»ºä¸€ä¸ªå…¨0çš„DataFrameä½œä¸ºæ¨¡æ¿
        df_clean = pd.DataFrame(0, index=raw_df.index, columns=self.valid_columns)
        # æ›´æ–°å­˜åœ¨çš„åˆ—
        common_cols = raw_df.columns.intersection(self.valid_columns)
        df_clean[common_cols] = raw_df[common_cols]
        
        X = df_clean.values
        
        # 2. ç¼ºå¤±å€¼å¤„ç†
        X = np.nan_to_num(X)
        
        # 3. æ ‡å‡†åŒ– + SVD æŠ•å½±
        X_std = (X - self.mean) / self.std
        X_svd = X_std @ self.V_k
        
        # 4. æœ€ç»ˆæ ‡å‡†åŒ–
        X_final = self.scaler.transform(X_svd)
        return X_final

# ================= 2. å››ç»´è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ =================
class ModelEvaluator:
    @staticmethod
    def calculate_metrics(model, X_test, y_test, model_name):
        results = {}
        
        # --- æŒ‡æ ‡ 1: è®¡ç®—æ•ˆç‡ (æ¨ç†è€—æ—¶) ---
        start_t = time.time()
        # è·‘å¤šæ¬¡å–å¹³å‡
        for _ in range(5): 
            _ = model.predict(X_test[:100])
        avg_infer_time_ms = (time.time() - start_t) / 5 * 1000 
        results['Inference_Time_1k_ms'] = avg_infer_time_ms
        
        # --- æŒ‡æ ‡ 2: æ¨¡å‹å¤§å° ---
        dump = pickle.dumps(model)
        size_mb = len(dump) / 1024 / 1024
        results['Model_Size_MB'] = size_mb
        
        # --- æŒ‡æ ‡ 3 & 4: å®æ—¶æ€§ä¸æœ‰æ•ˆå‡†ç¡®ç‡ ---
        y_pred = model.predict(X_test)
        
        # å¯»æ‰¾çŠ¶æ€åˆ‡æ¢ç‚¹
        events_true = []
        for i in range(1, len(y_test)):
            if y_test[i-1] == 0 and y_test[i] != 0:
                events_true.append({'idx': i, 'class': y_test[i]})
        
        detected_count = 0
        total_latency = 0
        valid_events = 0
        
        for event in events_true:
            # çª—å£ï¼šå‰ 20s (-1000æ ·æœ¬) åˆ° å 40s (+2000æ ·æœ¬)
            start_search = max(0, event['idx'] - 1000)
            end_search = min(len(y_pred), event['idx'] + 2000)
            
            window_pred = y_pred[start_search:end_search]
            
            try:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªé¢„æµ‹ä¸ºè¯¥ç±»åˆ«çš„ç´¢å¼•
                detect_offset = np.where(window_pred == event['class'])[0][0]
                detect_idx = start_search + detect_offset
                
                # è®¡ç®—æ—¶å»¶ (ç§’, å‡è®¾50Hz)
                latency = (detect_idx - event['idx']) * 0.02
                total_latency += abs(latency)
                detected_count += 1
                valid_events += 1
            except IndexError:
                pass
        
        base_acc = accuracy_score(y_test, y_pred)
        event_recall = detected_count / len(events_true) if len(events_true) > 0 else 0
        
        results['Effective_Accuracy'] = (base_acc * 0.6 + event_recall * 0.4)
        results['Avg_Latency_s'] = total_latency / valid_events if valid_events > 0 else 10.0
        
        return results

# ================= 3. ä¸»ç¨‹åº =================
def run_stage_5():
    print("="*60)
    print("ç¬¬äº”é˜¶æ®µï¼šæ¨¡å‹ä¼˜åŒ–ã€è¯„ä¼°ä¸æœ€ç»ˆé¢„æµ‹")
    print("="*60)
    
    # ================= è·¯å¾„é…ç½® (å·²ä¿®æ­£ä¸ºç»å¯¹è·¯å¾„) =================
    base_dir = "D:/bupt/code/python/æ•°å€¼è®¡ç®—æœŸæœ«ä½œä¸šæ•°æ®"
    train_path = os.path.join(base_dir, "train_data.csv")
    test_dir = os.path.join(base_dir, "test")
    output_dir = "prediction_results"  # ç»“æœä¿å­˜åœ¨å½“å‰è„šæœ¬ç›®å½•ä¸‹
    # ==============================================================

    # 1. åˆå§‹åŒ–å¹¶è¿è¡Œæµæ°´çº¿
    pipeline = EvaluationPipeline(train_file=train_path)
    if not pipeline.fit_pipeline():
        print("é”™è¯¯: æµæ°´çº¿åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return
    
    pipeline.train_models()
    
    # 2. è¯„ä¼°æ¨¡å‹
    print("\n" + "="*40)
    print("1. å¤šç»´æŒ‡æ ‡è¯„ä¼°")
    print("="*40)
    
    # åˆ‡åˆ†éªŒè¯é›†
    X_train, X_eval, y_train, y_eval = train_test_split(
        pipeline.X_train_final, pipeline.y_train, test_size=0.2, shuffle=False
    )
    
    eval_report = {}
    for name, model in pipeline.models.items():
        print(f"è¯„ä¼°æ¨¡å‹: {name}...")
        metrics = ModelEvaluator.calculate_metrics(model, X_eval, y_eval, name)
        eval_report[name] = metrics
        
    # æ‰“å°è¯„ä¼°è¡¨
    report_df = pd.DataFrame(eval_report).T
    print("\nè¯„ä¼°ç»“æœæ±‡æ€»:")
    print(report_df)
    report_df.to_csv('final_model_evaluation.csv')
    
    # é€‰æ‹©æœ€ä½³æ¨¡å‹
    best_score = -float('inf')
    best_model_name = None
    
    # ç®€å•çš„æ‰“åˆ†å…¬å¼: å‡†ç¡®ç‡æƒé‡é«˜ï¼Œæ—¶å»¶è¶Šå°è¶Šå¥½
    for name, metrics in eval_report.items():
        score = metrics['Effective_Accuracy'] * 100 - metrics['Avg_Latency_s'] * 1
        if score > best_score:
            best_score = score
            best_model_name = name
            
    print(f"\nğŸ† ç»¼åˆæœ€ä½³æ¨¡å‹: {best_model_name}")
    final_model = pipeline.models[best_model_name]
    
    # 3. æ¨¡å‹ä¼˜åŒ– (ä»¥éšæœºæ£®æ—å‰ªæä¸ºä¾‹)
    if best_model_name == 'RandomForest':
        print("\n" + "="*40)
        print("2. æ¨¡å‹ä¼˜åŒ– (å‰ªæ)")
        print("="*40)
        print(f"åŸå§‹å¤§å°: {eval_report['RandomForest']['Model_Size_MB']:.2f} MB")
        
        optimized_rf = RandomForestClassifier(n_estimators=20, max_depth=8, min_samples_leaf=5)
        optimized_rf.fit(X_train, y_train)
        
        opt_metrics = ModelEvaluator.calculate_metrics(optimized_rf, X_eval, y_eval, "RF_Optimized")
        print(f"ä¼˜åŒ–åå¤§å°: {opt_metrics['Model_Size_MB']:.2f} MB")
        print(f"ä¼˜åŒ–åå‡†ç¡®ç‡: {opt_metrics['Effective_Accuracy']:.4f}")
        
        if opt_metrics['Effective_Accuracy'] > 0.85:
            print("-> é‡‡çº³ä¼˜åŒ–åçš„æ¨¡å‹")
            final_model = optimized_rf
            
    # 4. éªŒè¯é›†æœ€ç»ˆé¢„æµ‹
    print("\n" + "="*40)
    print("3. æ‰§è¡Œæœ€ç»ˆé¢„æµ‹ (test æ–‡ä»¶å¤¹)")
    print("="*40)
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    if os.path.exists(test_dir):
        files = [f for f in os.listdir(test_dir) if f.endswith('.csv')]
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œå¼€å§‹é¢„æµ‹...")
        
        count = 0
        for f in files:
            file_path = os.path.join(test_dir, f)
            try:
                # è¯»å–åŸå§‹æ–‡ä»¶
                raw_df = pd.read_csv(file_path)
                
                # é¢„å¤„ç†
                X_test = pipeline.process_test_data(raw_df)
                
                # é¢„æµ‹
                y_pred = final_model.predict(X_test)
                
                # è¿½åŠ æ ‡ç­¾åˆ—
                result_df = raw_df.copy()
                result_df['labelArea'] = y_pred
                
                # ä¿å­˜
                save_path = os.path.join(output_dir, f"pred_{f}")
                result_df.to_csv(save_path, index=False)
                count += 1
                if count % 5 == 0:
                    print(f"  å·²å¤„ç† {count}/{len(files)} ä¸ªæ–‡ä»¶...")
                
            except Exception as e:
                print(f"  å¤„ç†æ–‡ä»¶ {f} å¤±è´¥: {e}")
                
        print(f"\næˆåŠŸï¼æ‰€æœ‰ {count} ä¸ªé¢„æµ‹ç»“æœå·²ä¿å­˜åœ¨ '{output_dir}' æ–‡ä»¶å¤¹ä¸­ã€‚")
    else:
        print(f"è­¦å‘Š: æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶å¤¹ {test_dir}")

    print("\n" + "="*60)
    print("ğŸ‰ å…¨æµç¨‹ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
    print("="*60)

if __name__ == "__main__":
    run_stage_5()